{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is an introduction to Machine Learning with Python's Scikit Learning Package\n",
    "\n",
    "We will be working on the handwritten digits dataset to fit models later predicting the digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset is a dictionary-like object that holds all the data and some metadata about the data. This data is stored in the .data member, which is a n_samples, n_features array. In the case of supervised problem, one or more response variables are stored in the .target member. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5. ,  3.4,  1.6,  0.4],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 4.8,  3. ,  1.4,  0.3],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 4.6,  3.2,  1.4,  0.2],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.1,  2.8,  4.7,  1.2],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 6.8,  2.8,  4.8,  1.4],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 6. ,  2.9,  4.5,  1.5],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 7.3,  2.9,  6.3,  1.8],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 6.5,  3. ,  5.5,  1.8],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 6.2,  2.8,  4.8,  1.8],\n",
       "       [ 6.1,  3. ,  4.9,  1.8],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 6.1,  2.6,  5.6,  1.4],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 5.9,  3. ,  5.1,  1.8]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_samples is basically the rows and n_features are the columns.\n",
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], \n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   5., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,  10.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,  16.,   9.,   0.],\n",
       "       ..., \n",
       "       [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
       "       [  0.,   0.,   2., ...,  12.,   0.,   0.],\n",
       "       [  0.,   0.,  10., ...,  12.,   1.,   0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets try it for the digits dataset\n",
    "digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# digits.target gives the ground truth for the digit dataset, that is the number corresponding to each digit image \n",
    "# that we are trying to learn:\n",
    "digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of the data arrays\n",
    "The data is always a 2D array, shape (n_samples, n_features), although the original data may have had a different shape. \n",
    "In the case of the digits, each original sample is an image of shape (8, 8) and can be accessed using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   5.,  13.,   9.,   1.,   0.,   0.],\n",
       "       [  0.,   0.,  13.,  15.,  10.,  15.,   5.,   0.],\n",
       "       [  0.,   3.,  15.,   2.,   0.,  11.,   8.,   0.],\n",
       "       [  0.,   4.,  12.,   0.,   0.,   8.,   8.,   0.],\n",
       "       [  0.,   5.,   8.,   0.,   0.,   9.,   8.,   0.],\n",
       "       [  0.,   4.,  11.,   0.,   1.,  12.,   7.,   0.],\n",
       "       [  0.,   2.,  14.,   5.,  10.,  12.,   0.,   0.],\n",
       "       [  0.,   0.,   6.,  13.,  10.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning and predicting\n",
    "In the case of the digits dataset, the task is to predict, given an image, which digit it represents. We are given samples of each of the 10 possible classes (the digits zero through nine) on which we fit an estimator to be able to predict the classes to which unseen samples belong.\n",
    "\n",
    "In scikit-learn, an estimator for classification is a Python object that implements the methods fit(X, y) and predict(T).\n",
    "\n",
    "An example of an estimator is the class sklearn.svm.SVC that implements support vector classification. The constructor of an estimator takes as arguments the parameters of the model, but for the time being, we will consider the estimator as a black box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.001, C=100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the parameters of the model\n",
    "In this example we set the value of gamma manually. It is possible to automatically find good values for the parameters by using tools such as grid search and cross validation.\n",
    "\n",
    "We call our estimator instance 'clf', as it is a classifier. It now must be fitted to the model, that is, it must learn from the model. This is done by passing our training set to the fit method. As a training set, let us use all the images of our dataset apart from the last one. We select this training set with the [:-1] Python syntax, which produces a new array that contains all but the last entry of digits.data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target is the feature that is to be predicted. Here, data would be our x and target would be our y. We are taking\n",
    "# training data from both x and y and we then try to fit our estimator on it. Not that clf is an instance of our estimator.\n",
    "clf.fit(digits.data[:-1], digits.target[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can predict new values, in particular, the digit of our last image in the digits dataset, which we have not used to train the classifier: i.e. we have kept that aside as our test data. Usually we go by the 80-20 rule where 80% of our data would be used for training and 20% for testing. Anyways, for this tutorial, we are going with a 90-10 model cos our sample size is very little and we need a significantly large data set to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets try and predict the last digit\n",
    "clf.predict(digits.data[-1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction says that its an \"8\". Lets see what our actual digit is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,  10.,  14.,   8.,   1.,   0.,   0.,   0.,   2.,  16.,\n",
       "         14.,   6.,   1.,   0.,   0.,   0.,   0.,  15.,  15.,   8.,  15.,\n",
       "          0.,   0.,   0.,   0.,   5.,  16.,  16.,  10.,   0.,   0.,   0.,\n",
       "          0.,  12.,  15.,  15.,  12.,   0.,   0.,   0.,   4.,  16.,   6.,\n",
       "          4.,  16.,   6.,   0.,   0.,   8.,  16.,  10.,   8.,  16.,   8.,\n",
       "          0.,   0.,   1.,   8.,  12.,  14.,  12.,   1.,   0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f934f88160>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(digits.images[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f934ea5240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ooooh that's an 8??? Doesn't  look so. Lets try and print another image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f934fea5c0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(digits.images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwIHECBxIjMCBxAgcSIzAgcT+B4HUgSjOZJ3sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f934f5ed68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that looks like a \"1\"\n",
    "\n",
    "### Alright so we can all agree that it is a challenging task: the images are of poor resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model persistence Using Picke\n",
    "It is possible to save a model in the scikit by using Python’s built-in persistence model, namely pickle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving our model (the estimator) as a pickle\n",
    "s = pickle.dumps(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How to load it later??\n",
    "clf2 = pickle.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rhomi\\Anaconda2\\envs\\data\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.predict(digits.data[407])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it says its a \"One\". Lets just see if it's right shall we??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f9355ad208>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(digits.images[407])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/g8fE45mGhWFJAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f9355633c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, that's pretty spot on!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little tip on using Pickle\n",
    "Note that pickle has some security and maintainability issues.\n",
    "In the specific case of the scikit, it may be more interesting to use joblib’s replacement of pickle (joblib.dump & joblib.load), which is more efficient on big data, but can only pickle to the disk and not to a string:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is how we do it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, 'filename.pkl') \n",
    "clf3 = joblib.load('filename.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more info on joblib refer https://pythonhosted.org/joblib/persistence.html\n",
    "For more info on model persistence refer http://scikit-learn.org/stable/modules/model_persistence.html#model-persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:data]",
   "language": "python",
   "name": "conda-env-data-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
